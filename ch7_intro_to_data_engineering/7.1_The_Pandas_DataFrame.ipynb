{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Video Explanation Here!](https://youtu.be/31NuV3K-cGw)\n",
    "\n",
    "### Pandas\n",
    "\n",
    "Pandas is a Python library that allows us to analyze tabular data. If you have used Microsoft Excel or a similar spreadsheet tool, you've used a user interface to do some of the things we can do with Pandas. If you've worked on data analysis with R, you have already done some programmatic data analysis like we will do with Pandas. \n",
    "\n",
    "Pandas represents tabular data inside of an objetc called a `DataFrame`. Each column header points to a `Series` (a `pandas` object that contains a collection of values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, when we install `pandas`, it pulls in its own dependency on a library called `numpy`. We are going to talk about that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas `DataFrame` Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('birds.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` has attributes:\n",
    "\n",
    "- index: An Index object. The values are the row/index labels.\n",
    "- columns: An index object. The values are the column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Indexing and Selection\n",
    "\n",
    "A `DataFrame` maps a column name to a `Series` of column data. Because the `__getitem__` behavior of a `DataFrame` returns a column, you can think about a DataFrame as a sort of dictionary (although there's more to it of courseâ€”for sorting or filtering rows, for example, we need a row-oriented representation of the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['specimen_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.specimen_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add a new column the way that we would add a new key value pair to a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description'] = \"Specimen \" + df[\"specimen_id\"] + \" is a \" + df.species + \" and weighs \" + df.weight.astype(str) + \" ounces.\"\n",
    "print(df['Description'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can transpose a dataframe.\n",
    "\n",
    "**Transpose** means to switch the rows and columns. This might make sense if you're refrencing individual specimens more often than their characteristics, or if you have more characteristics per specimen than you have specimens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can also get ahold of the values as a 2d matrix.\n",
    "\n",
    "Remember, we sometimes need a matrix representation of our data for sorting, filtering, or other operations that focus on the rows (specimens) rather than the columns (specime characteristics).\n",
    "\n",
    "We also often need a representation like this to feed data into existing machine learning model libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, again, that the data type of the thing we are looking at above is not the Python `list`: instead, it says **array**. We'll discuss that further later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many kinds of `DataFrame` indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3, 'weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc` stands for \"index location.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the numeric index doesn't mean anything to you and you'd like to index on one of the column values, you can do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('specimen_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['7ss24g6t7f2dr4h32']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even set a multi-index on multiple characteristics. This would be useful if, for example, a `specimen_id` might be duplicated among the specimens but never within a species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index() # resets the index to the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['specimen_id', 'species'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[('g6t7f2dr4h327ss24', 'oriole'), 'Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that after resetting the index, numeric index location still works. Here we are getting a slice of the dataframe representing the third through the fifth row and the first column. (the indices are also presented here, which is why you see `specimen_id` and `species` in the output.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2:5, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2:5, 0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking\n",
    "\n",
    "You can filter for a window of your dataframe for which a certain condition is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking\n",
    "df[df['weight'] < 4.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['weight'] < 3.0) & (df['weight'] > 2.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame` Operations\n",
    "\n",
    "Pandas `DataFrame` objects allow element-wise operations.\n",
    "\n",
    "You can even use ufuncs to *preserve index and column labels* in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "df = pd.DataFrame(np.random.randint(0, 10, (3,4)), columns=['A','B','C','D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(df * np.pi / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames\n",
    "\n",
    "`DataFrames` provide several operations that return an instance of a `DataFrame` from vaaious file formats.\n",
    "\n",
    "```\n",
    "df_from_csv = pd.read_csv('/path/to/file.csv')\n",
    "df_from_web_csv = pd.read_csv('https://data.cityofchicago.org/api/views/x8fc-8rcq/rows.csv?accessType=DOWNLOAD')\n",
    "df_from_json_csv = pd.read_json('/path/to/file.json')\n",
    "df_from_web_json_csv = pd.read_json('https://website.com/resource')\n",
    "df_from_excel = pd.read_excel('path/to/file.xlsx')\n",
    "```\n",
    "\n",
    "You can also, if you like, make one from a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "                  \"name\" : [\"Jupiter\", \"Saturn\", \"Neptune\", \"Earth\"],\n",
    "                  \"habitable_zone\": [False, False, False, False],\n",
    "                  \"gaseous\": [True, True, True, False]\n",
    "                  \n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data with DataFrames\n",
    "\n",
    "I could stand here and walk you through an entire catalog of the methods available on a `DataFrame`. I won't, though: that's not how you would learn to use a new library or tool in a professional or research context. Rather, you would: \n",
    "\n",
    "1. start with a **use case**: a specific problem to solve.\n",
    "2. look for ways to solve your problem by:\n",
    "    - Asking Experts\n",
    "    - Searching the Internet\n",
    "    - Checking the Indices of good books\n",
    "    \n",
    "As you gain experience in this industry, you are going to learn how to do more things. But even more importantly, you will improve your efficiency at _learning_ new things by:\n",
    "- Meeting experts, who you can text/email withe questions\n",
    "- Learning better strategies for searching the internet\n",
    "- Building a collection of authors and books that you trust\n",
    "- Developing intuition for how things work that sometimes helps you guess what's going on.\n",
    "\n",
    "For example, from looking at usage examples for `pandas` like the one below, you can get an idea of what the library is good for and what other methods it probably has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = pd.read_csv('metrics.csv') \\\n",
    "        .assign(year=lambda row: row[\"Period Start\"].apply(lambda x: x[-4:])) \\\n",
    "        .assign(activity_year=lambda row: row[\"Activity\"] + \" (\" + row[\"year\"] + \")\") \\\n",
    "        .assign(average_days_to_complete_activity=lambda row: row[\"Average Days to Complete Activity\"].apply(lambda x: float(x))) \\\n",
    "        .where(lambda x: x['Activity'] == 'Alley Grading-Unimproved') \\\n",
    "        .groupby('activity_year') \\\n",
    "        .agg({\n",
    "             'Target Response Days': 'max', \n",
    "             'average_days_to_complete_activity': 'mean'\n",
    "            }) \\\n",
    "        .reset_index() \\\n",
    "        .assign(average_schedule_slippage=lambda row: row.average_days_to_complete_activity - row['Target Response Days']) \\\n",
    "        .sort_values('average_schedule_slippage', ascending=False)\n",
    "\n",
    "aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block of code, we use `pandas` to take some data in a csv and answer the question \"Out of all the years that Chicago has recorded the completion of Alley Grading-Unimproved projects, in which of those years has the schedule for the projects slipped the most, on average, compared to its target?\n",
    "\n",
    "**In the process we:**\n",
    "- Make a tabular representation of a csv\n",
    "- Assign new columns to it to represent the year\n",
    "- Filter it for the activities we want to look at\n",
    "- Group it by activity year\n",
    "- Take some aggregate statistics\n",
    "- Use those aggregate statistics to calculate schedule slippage\n",
    "- Put the activity years in descending order from most to least schedule slippage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidenote: The Aggregation Functions\n",
    "\n",
    "> Here are the 13 aggregating functions available in Pandas and quick summary of what it does.\n",
    "\n",
    "- mean(): Compute mean of groups\n",
    "- sum(): Compute sum of group values\n",
    "- size(): Compute group sizes\n",
    "- count(): Compute count of group\n",
    "- std(): Standard deviation of groups\n",
    "- var(): Compute variance of groups\n",
    "- sem(): Standard error of the mean of groups\n",
    "- describe(): Generates descriptive statistics\n",
    "- first(): Compute first of group values\n",
    "- last(): Compute last of group values\n",
    "- nth() : Take nth value, or a subset if n is a list\n",
    "- min(): Compute min of group values\n",
    "- max(): Compute max of group values\n",
    "    \n",
    "Source: [Python and R Tips](https://cmdlinetips.com/2019/10/pandas-groupby-13-functions-to-aggregate/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
