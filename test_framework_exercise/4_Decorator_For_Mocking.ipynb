{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our testing framework is coming along!\n",
    "\n",
    "Now we have a relatively functional test runner to go along with our matchers! Let's import our progress so far on our test suite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix_test.matchers import FailedAssertion, Assertion, assert_that\n",
    "from phoenix_test.test import Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look, I'll be honest: I'm getting pretty tired of implementing a crappy `find_twos` in each of these lessons. So for now, we're gonna graduate to pretending we got promoted to Test Engineer for the Python Programming Language, responsible for writing tests to evaluate the Python builtins themselves. I'm sure the Python Software Foundation put our checks in the mail today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortedTests(Test):\n",
    "    def test_sort_integers(self):\n",
    "        assert_that(sorted([3, 1, 2])).equals([1, 2, 3])\n",
    "\n",
    "    def test_sort_strings(self):\n",
    "        assert_that(sorted([\"C\", \"A\", \"B\"])).equals([\"A\", \"B\", \"C\"])\n",
    "\n",
    "class DirTests(Test):\n",
    "    def test_dir_any_object(self):\n",
    "        assert_that(dir(object)).has_items('__init__')\n",
    "\n",
    "    def test_dir_custom_object(self):\n",
    "        class NewClass():\n",
    "            some_attribute = \"Hello!\"\n",
    "        assert_that(dir(NewClass)).has_items('some_attribute')\n",
    "\n",
    "Test.run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have the following code that represents a scientific experiment. We want to be able to sort our subjects into control and experimental groups for running the trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "class Experiment():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.subjects = []\n",
    "\n",
    "class Subject:\n",
    "    pass\n",
    "        \n",
    "class Trial():\n",
    "    def __init__(self, \n",
    "                 control, \n",
    "                 experimental, \n",
    "                 experiment_proportion = 0.3, \n",
    "                 subjects=[]):\n",
    "        self.control = control\n",
    "        self.experimental = experimental\n",
    "        self.experiment_proportion = experiment_proportion\n",
    "        self.subjects = subjects\n",
    "    \n",
    "    def sort_subjects(self):\n",
    "        for subject in self.subjects:\n",
    "            if random.random() < self.experiment_proportion:\n",
    "                self.experimental.subjects.append(subject)\n",
    "            else:\n",
    "                self.control.subjects.append(subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, experiments are serious business, so we want to write some tests to make sure that our `Trial` is doing what we think it's doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialTests(Test):\n",
    "    \n",
    "    def setup(self):\n",
    "        experimental = Experiment(\"Candy for breakfast\")\n",
    "        control = Experiment(\"A normal, sensible breakfast\")\n",
    "        subjects = [Subject() for i in range(10)]\n",
    "        self.trial = Trial(\n",
    "            control=control, \n",
    "            experimental=experimental,\n",
    "            subjects=subjects\n",
    "        )\n",
    "    \n",
    "    def test_default(self):\n",
    "        assert_that(self.trial.subjects).has_size(10)\n",
    "        self.trial.sort_subjects()\n",
    "        print(f\"Control group size: {len(self.trial.control.subjects)}\")\n",
    "        print(f\"Experimental group size: {len(self.trial.experimental.subjects)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have done something unusual here: I am printing out some values from the test to demonstrate how the subjects are split into their control and experimental groups. Run the line of code below a few times. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrialTests().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the above several times, you'll notice that the control group size and the experimental group size are different from run to run. We call code like this **non-deterministic.** We're using random sorting ensure that our control and experimental group sorting isn't biased, but that means that we cannot check exactly what this code is doing as written.\n",
    "\n",
    "Luckily, we have some options for situations like this. The most common one, especially in an object-oriented language, is **dependency injection**. Here's how that looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialWithDI(Trial):\n",
    "    def __init__(self, \n",
    "                 control, \n",
    "                 experimental, \n",
    "                 sorting_function,\n",
    "                 subjects=[]):\n",
    "        super().__init__(control,experimental,0.3,subjects)\n",
    "        self.sorting_function = sorting_function\n",
    "        \n",
    "    def sort_subjects(self):\n",
    "        for subject in self.subjects:\n",
    "            if self.sorting_function():\n",
    "                self.experimental.subjects.append(subject)\n",
    "            else:\n",
    "                self.control.subjects.append(subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the `sort_subjects` function is a _dependency_ upon which `ExperimentWithDI` depends. Sometimes dependency injection is considered an implementation of an idea called **inversion of control**, that is:\n",
    "\n",
    "1. The \"traditional\" direction of control in an object-oriented language is that superclasses pass behavior \"down\" to subclasses\n",
    "2. In dependency injection, dependencies pass behavior \"up\" into the classes that accept them as dependency attributes\n",
    "\n",
    "Now, part of the above isn't great, which is what we're doing to the `experiment_proportion`. The subclass doesn't accept it in the initializer, instead calling the superclass initializer with a throwaway value. The subclass then overrides `sort_subjects` to _not use_ experiment_proportion at all. It's not the _worst_ possible offender of removing behavior in subclasses, but it's weird and confusing. This is the kind of place where I might put a comment in some code to explain why I'm doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: \n",
    "\n",
    "Add a comment to the `ExperimentWithDI` code to explain why we do not need `experiment_proportion` anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, so anyway.\n",
    "\n",
    "Here's how we could use dependency injection to surgically remove the randomness of the `Trial` class for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialTests(Test):\n",
    "    \n",
    "    def setup(self):\n",
    "        experimental = Experiment(\"Candy for breakfast\")\n",
    "        control = Experiment(\"A normal, sensible breakfast\")\n",
    "        subjects = [Subject() for i in range(10)]\n",
    "        \n",
    "        self.trial = TrialWithDI(\n",
    "            control=control, \n",
    "            experimental=experimental,\n",
    "            sorting_function=lambda: True,\n",
    "            subjects=subjects\n",
    "        )\n",
    "    \n",
    "    def test_default(self):\n",
    "        assert_that(self.trial.subjects).has_size(10)\n",
    "        self.trial.sort_subjects()\n",
    "        print(f\"Control group size: {len(self.trial.control.subjects)}\")\n",
    "        print(f\"Experimental group size: {len(self.trial.experimental.subjects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrialTests().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sorting function always returns true, so all of the subjects get sorted into the `experimental` group. We can use a test like this to evaluate all the _other_ mechaics of our `TrialWithDI` class, then pass in `random.random() < 0.3` for the _real_ implementation to get the random effect we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try something wild.\n",
    "\n",
    "Can we write a `mock` decorator to handle injecting some mock behavior for us, without reimplementing the `Trial` class?\n",
    "\n",
    "ðŸš¨ðŸš¨The following code was written by a professional developer on a closed course. Do not try this at home.ðŸš¨ðŸš¨\n",
    "\n",
    "![](../images/car_drift.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock(call, to_return):\n",
    "    def decorator(func):\n",
    "        def wrapper(testobject):\n",
    "            module = eval('.'.join(call.split('.')[:-1]))\n",
    "            module_function_name = call.split('.')[-1]\n",
    "            module_function_body = getattr(module, module_function_name)\n",
    "            setattr(module, module_function_name, lambda: to_return)\n",
    "            \n",
    "            func(testobject)\n",
    "            \n",
    "            setattr(module, module_function_name, module_function_body)\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialTests(Test):\n",
    "    \n",
    "    def setup(self):\n",
    "        experimental = Experiment(\"Candy for breakfast\")\n",
    "        control = Experiment(\"A normal, sensible breakfast\")\n",
    "        subjects = [Subject() for i in range(10)]\n",
    "        self.trial = Trial(\n",
    "            control=control, \n",
    "            experimental=experimental,\n",
    "            subjects=subjects\n",
    "        )\n",
    "    \n",
    "    @mock(call='random.random', to_return=0.1)\n",
    "    def test_default(self):\n",
    "        assert_that(self.trial.subjects).has_size(10)\n",
    "        self.trial.sort_subjects()\n",
    "        print(f\"Control group size: {len(self.trial.control.subjects)}\")\n",
    "        print(f\"Experimental group size: {len(self.trial.experimental.subjects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrialTests().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. So. Let's evaluate this code. But before we can do that, let's make sure we understand what this code is doing.\n",
    "\n",
    "### Challenge:\n",
    "\n",
    "1. Go through the `mock` decorator, line by line, and figure out what it is doing. \n",
    "\n",
    "You have seen this function before:\n",
    "\n",
    "- `getattr`\n",
    "\n",
    "You are likely to need to look up:\n",
    "\n",
    "- `eval`\n",
    "- `setattr`\n",
    "\n",
    "2. What is going to happen if we don't include `setattr(module, module_function_name, module_function_body)` in the mock method? If you need a hint, you can comment out that line, run the mock method, run the blocks of code that use it, and then run the line below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Does doing this with the code seem like a good idea to you? What are the benefits and risks of what we've done here?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
